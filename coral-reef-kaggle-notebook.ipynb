{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-09T17:39:10.547305Z","iopub.execute_input":"2022-02-09T17:39:10.547778Z","iopub.status.idle":"2022-02-09T17:39:10.572589Z","shell.execute_reply.started":"2022-02-09T17:39:10.547664Z","shell.execute_reply":"2022-02-09T17:39:10.571596Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5  # clone\n!cd yolov5\n!pip install -r ./yolov5/requirements.txt  # install","metadata":{"execution":{"iopub.status.busy":"2022-02-09T17:39:10.574656Z","iopub.execute_input":"2022-02-09T17:39:10.574998Z","iopub.status.idle":"2022-02-09T17:39:26.972532Z","shell.execute_reply.started":"2022-02-09T17:39:10.574956Z","shell.execute_reply":"2022-02-09T17:39:26.971446Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport os\nimport ast\nimport shutil","metadata":{"execution":{"iopub.status.busy":"2022-02-09T17:39:26.976511Z","iopub.execute_input":"2022-02-09T17:39:26.976736Z","iopub.status.idle":"2022-02-09T17:39:27.298753Z","shell.execute_reply.started":"2022-02-09T17:39:26.976704Z","shell.execute_reply":"2022-02-09T17:39:27.297599Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tensorflow-great-barrier-reef/train.csv\", index_col=\"image_id\")\ntrain.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T17:39:27.302170Z","iopub.execute_input":"2022-02-09T17:39:27.303084Z","iopub.status.idle":"2022-02-09T17:39:27.385424Z","shell.execute_reply.started":"2022-02-09T17:39:27.303037Z","shell.execute_reply":"2022-02-09T17:39:27.384418Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"img = cv2.imread(\"../input/tensorflow-great-barrier-reef/train_images/video_0/978.jpg\")\n# from cv2 import cv2_imshow\n\nstart_pt = (825, 224)\nend_pt = (875, 259)\ncolor = (0, 0, 255)\nthickness = 2\nimage = cv2.rectangle(img, start_pt, end_pt, color, thickness)\nplt.imshow(image)\nprint(image.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T17:39:27.387003Z","iopub.execute_input":"2022-02-09T17:39:27.389066Z","iopub.status.idle":"2022-02-09T17:39:27.882576Z","shell.execute_reply.started":"2022-02-09T17:39:27.389016Z","shell.execute_reply":"2022-02-09T17:39:27.880965Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!mkdir -p ./datasets/coral/labels\n!mkdir -p ./datasets/coral/images\n\npath_to_txt_folder = \"./datasets/coral/labels\"\nfinal_path_to_images = \"./datasets/coral/images\"\n\ndef txt_data(path):\n    for folder in os.listdir(path):\n        path_to_folder = os.path.join(path, folder)\n        _, video_id = folder.split(\"_\")\n\n        for image in os.listdir(path_to_folder):\n            path_to_image = os.path.join(path_to_folder, image)\n\n            image_id, img_ext = image.split(\".\")\n            image_match = video_id + \"-\" + image_id\n\n            img_temp = cv2.imread(path_to_image)\n            height, width, channels = img_temp.shape\n\n            image_data = train.loc[image_match]\n            annotation_list = ast.literal_eval(image_data.annotations)\n\n            if bool(annotation_list) == True:\n                path_to_file = os.path.join(path_to_txt_folder, image_match + \".txt\")\n                file_ = open(path_to_file, \"w\")\n                for i in annotation_list:\n                    x_min = i['x']\n                    y_min = i['y']\n                    box_width = i['width']\n                    box_height = i['height']\n                    class_label=str(0)\n                    x_min = str(round((x_min+(box_width/2))/width, 10))\n                    y_min = str(round((y_min+(box_height/2))/height, 10))\n                    box_width = str(round(box_width/width, 10))\n                    box_height = str(round(box_height/height, 10))\n                    file_.write(class_label+\" \"+x_min+\" \"+y_min+\" \"+box_width+\" \"+\" \"+box_height)\n                file_.close()\n    \n                image_new_name = os.path.join(final_path_to_images, image_match + \".\" + img_ext)\n#             new_path_to_image = os.path.join(final_path_to_images, image_new_name)\n                shutil.copyfile(path_to_image, image_new_name)\n\ntxt_data(\"../input/tensorflow-great-barrier-reef/train_images\")","metadata":{"execution":{"iopub.status.busy":"2022-02-09T17:39:27.883792Z","iopub.execute_input":"2022-02-09T17:39:27.884139Z","iopub.status.idle":"2022-02-09T17:52:01.720965Z","shell.execute_reply.started":"2022-02-09T17:39:27.884095Z","shell.execute_reply":"2022-02-09T17:52:01.719645Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"img = cv2.imread(\"./datasets/coral/images/0-978.jpg\")\n# from google.colab.patches import cv2_imshow\n\nstart_pt = (825, 224)\nend_pt = (875, 259)\ncolor = (0, 0, 255)\nthickness = 2\nimage = cv2.rectangle(img, start_pt, end_pt, color, thickness)\nplt.imshow(image)\nprint(image.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T17:52:01.722886Z","iopub.execute_input":"2022-02-09T17:52:01.723252Z","iopub.status.idle":"2022-02-09T17:52:02.170726Z","shell.execute_reply.started":"2022-02-09T17:52:01.723170Z","shell.execute_reply":"2022-02-09T17:52:02.169824Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"shutil.copyfile(\"../input/coral-yaml/coral.yaml\", \"./yolov5/data/coral.yaml\")\nshutil.copyfile(\"../input/coral-yaml/hyp.yaml\", \"./yolov5/data/hyps/hyp.yaml\")","metadata":{"execution":{"iopub.status.busy":"2022-02-09T17:52:02.172796Z","iopub.execute_input":"2022-02-09T17:52:02.173416Z","iopub.status.idle":"2022-02-09T17:52:02.196270Z","shell.execute_reply.started":"2022-02-09T17:52:02.173375Z","shell.execute_reply":"2022-02-09T17:52:02.195310Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb_key\")\n\n!pip install wandb\n!wandb login $secret_value_0","metadata":{"execution":{"iopub.status.busy":"2022-02-09T17:52:02.197875Z","iopub.execute_input":"2022-02-09T17:52:02.198259Z","iopub.status.idle":"2022-02-09T17:52:16.679815Z","shell.execute_reply.started":"2022-02-09T17:52:02.198184Z","shell.execute_reply":"2022-02-09T17:52:16.678670Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"## Train YOLOv5m on coral_dataset for 3 epochs\n!python ./yolov5/train.py --img 1280 --rect --batch 8 --epochs 15 --data ./yolov5/data/coral.yaml --hyp ./yolov5/data/hyps/hyp.yaml --weights yolov5m.pt","metadata":{"execution":{"iopub.status.busy":"2022-02-09T21:36:46.291815Z","iopub.execute_input":"2022-02-09T21:36:46.292851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nckpt_path = \"./yolov5/runs/train/exp/weights/best.pt\"\n\nmodel = torch.hub.load('./yolov5', 'custom',\n                           path=ckpt_path,\n                           source='local',\n                       force_reload=True)\n\nmodel.conf = 0.20\nmodel.iou = 0.45\n\nresults = model(\"./datasets/coral/images/0-4600.jpg\")\nresults.print()\nresults.pandas().xyxy[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rand_set = random.choices(os.listdir(\"./datasets/coral/labels\"), k=10)\nfor i in rand_set:\n    image, _ = i.split(\".\")\n    file_name = os.path.join(\"./datasets/coral/images\", image + \".jpg\")\n    results = model(file_name)\n    print(file_name)\n    results.print()\n    results.pandas().xyxy[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import greatbarrierreef\n\nenv = greatbarrierreef.make_env()   # initialize the environment\niter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:10:15.929709Z","iopub.execute_input":"2022-02-07T15:10:15.930178Z","iopub.status.idle":"2022-02-07T15:10:16.002354Z","shell.execute_reply.started":"2022-02-07T15:10:15.93014Z","shell.execute_reply":"2022-02-07T15:10:16.00128Z"},"trusted":true},"execution_count":null,"outputs":[]}]}