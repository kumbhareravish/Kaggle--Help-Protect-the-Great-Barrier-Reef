{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5  # clone\n!cd yolov5\n!pip install -r ./yolov5/requirements.txt  # install","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport os\nimport ast\nimport shutil","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:17:14.655540Z","iopub.execute_input":"2022-02-14T17:17:14.656195Z","iopub.status.idle":"2022-02-14T17:17:14.701874Z","shell.execute_reply.started":"2022-02-14T17:17:14.656085Z","shell.execute_reply":"2022-02-14T17:17:14.701133Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/tensorflow-great-barrier-reef/train.csv\", index_col=\"image_id\")\ntrain.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:17:18.133579Z","iopub.execute_input":"2022-02-14T17:17:18.133860Z","iopub.status.idle":"2022-02-14T17:17:18.181489Z","shell.execute_reply.started":"2022-02-14T17:17:18.133831Z","shell.execute_reply":"2022-02-14T17:17:18.180762Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"img = cv2.imread(\"../input/tensorflow-great-barrier-reef/train_images/video_0/978.jpg\")\n# from cv2 import cv2_imshow\n\nstart_pt = (825, 224)\nend_pt = (875, 259)\ncolor = (0, 0, 255)\nthickness = 2\nimage = cv2.rectangle(img, start_pt, end_pt, color, thickness)\nplt.imshow(image)\nprint(image.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:17:21.395311Z","iopub.execute_input":"2022-02-14T17:17:21.395760Z","iopub.status.idle":"2022-02-14T17:17:21.852724Z","shell.execute_reply.started":"2022-02-14T17:17:21.395718Z","shell.execute_reply":"2022-02-14T17:17:21.852065Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!mkdir -p ./datasets/coral/labels\n!mkdir -p ./datasets/coral/images\n\npath_to_txt_folder = \"./datasets/coral/labels\"\nfinal_path_to_images = \"./datasets/coral/images\"\n\ndef txt_data(path):\n    for folder in os.listdir(path):\n        path_to_folder = os.path.join(path, folder)\n        _, video_id = folder.split(\"_\")\n\n        for image in os.listdir(path_to_folder):\n            path_to_image = os.path.join(path_to_folder, image)\n\n            image_id, img_ext = image.split(\".\")\n            image_match = video_id + \"-\" + image_id\n\n            img_temp = cv2.imread(path_to_image)\n            height, width, channels = img_temp.shape\n\n            image_data = train.loc[image_match]\n            annotation_list = ast.literal_eval(image_data.annotations)\n\n            if bool(annotation_list) == True:\n                path_to_file = os.path.join(path_to_txt_folder, image_match + \".txt\")\n                file_ = open(path_to_file, \"w\")\n                for i in annotation_list:\n                    x_min = i['x']\n                    y_min = i['y']\n                    box_width = i['width']\n                    box_height = i['height']\n                    class_label=str(0)\n                    x_min = str(round((x_min+(box_width/2))/width, 10))\n                    y_min = str(round((y_min+(box_height/2))/height, 10))\n                    box_width = str(round(box_width/width, 10))\n                    box_height = str(round(box_height/height, 10))\n                    file_.write(class_label+\" \"+x_min+\" \"+y_min+\" \"+box_width+\" \"+\" \"+box_height)\n                file_.close()\n    \n                image_new_name = os.path.join(final_path_to_images, image_match + \".\" + img_ext)\n#             new_path_to_image = os.path.join(final_path_to_images, image_new_name)\n                shutil.copyfile(path_to_image, image_new_name)\n\ntxt_data(\"../input/tensorflow-great-barrier-reef/train_images\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = cv2.imread(\"./datasets/coral/images/0-978.jpg\")\n# from google.colab.patches import cv2_imshow\n\nstart_pt = (825, 224)\nend_pt = (875, 259)\ncolor = (0, 0, 255)\nthickness = 2\nimage = cv2.rectangle(img, start_pt, end_pt, color, thickness)\nplt.imshow(image)\nprint(image.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.copyfile(\"../input/coralyaml/coral.yaml\", \"./yolov5/data/coral.yaml\")\nshutil.copyfile(\"../input/coralyaml/hyp.yaml\", \"./yolov5/data/hyps/hyp.yaml\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb_key\")\n\n!pip install wandb\n!wandb login $secret_value_0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Train YOLOv5m on coral_dataset for 3 epochs\n#!python ./yolov5/train.py --img 1280 --rect --batch 8 --epochs 15 --data ./yolov5/data/coral.yaml --hyp ./yolov5/data/hyps/hyp.yaml --weights yolov5m.pt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nckpt_path = \"../input/easy-firefly-weights/best_yolov5s_0.78_precision_logical_oath_36.pt\"\n\nmodel = torch.hub.load('./yolov5', 'custom',\n                           path=ckpt_path,\n                           source='local',\n                       force_reload=True)\n\nmodel.conf = 0.01\nmodel.iou = 0.25\n\n#results = model(\"./datasets/coral/images/0-4600.jpg\")\n#results.print()\n#results.pandas().xyxy[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:17:30.815787Z","iopub.execute_input":"2022-02-14T17:17:30.816059Z","iopub.status.idle":"2022-02-14T17:17:35.075217Z","shell.execute_reply.started":"2022-02-14T17:17:30.816029Z","shell.execute_reply":"2022-02-14T17:17:35.074434Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"results = model(\"../input/tensorflow-great-barrier-reef/train_images/video_1/100.jpg\")\n#results.print()\nresults_df=results.pandas().xyxy[0]\nresults_df","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:17:38.394583Z","iopub.execute_input":"2022-02-14T17:17:38.395310Z","iopub.status.idle":"2022-02-14T17:17:38.450126Z","shell.execute_reply.started":"2022-02-14T17:17:38.395267Z","shell.execute_reply":"2022-02-14T17:17:38.449437Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def result_string_calculator(results_dataframe):\n    if results_dataframe.shape[0] != 0:\n        for index,row in results_dataframe.iterrows():\n            x_center = row['xmin'] + ((row['xmax'] - row['xmin'])/2)\n            y_center = row['ymin'] + ((row['ymax'] - row['ymin'])/2)\n            height= row['ymax'] - row['ymin']\n            width = row['xmax'] - row['xmin']\n            confidence_score = row['confidence']\n        output_string = \"{} {} {} {} {}\".format(confidence_score,round(x_center),round(y_center),round(width),round(height))\n    else:\n        output_string = \"0 0 0 0 0\"\n    return output_string","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:18:04.407400Z","iopub.execute_input":"2022-02-14T17:18:04.407718Z","iopub.status.idle":"2022-02-14T17:18:04.414642Z","shell.execute_reply.started":"2022-02-14T17:18:04.407663Z","shell.execute_reply":"2022-02-14T17:18:04.413929Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"result_string_calculator(results_df)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:18:04.615662Z","iopub.execute_input":"2022-02-14T17:18:04.616208Z","iopub.status.idle":"2022-02-14T17:18:04.621872Z","shell.execute_reply.started":"2022-02-14T17:18:04.616168Z","shell.execute_reply":"2022-02-14T17:18:04.621198Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import greatbarrierreef\nenv = greatbarrierreef.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\nfor (pixel_array, sample_prediction_df) in iter_test:\n    results = model(pixel_array)\n    results_df=results.pandas().xyxy[0]\n    sample_prediction_df['annotations'] =  result_string_calculator(results_df) # make your predictions here\n    env.predict(sample_prediction_df)   # register your predictions","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:18:07.709074Z","iopub.execute_input":"2022-02-14T17:18:07.709337Z","iopub.status.idle":"2022-02-14T17:18:07.781283Z","shell.execute_reply.started":"2022-02-14T17:18:07.709307Z","shell.execute_reply":"2022-02-14T17:18:07.780541Z"},"trusted":true},"execution_count":9,"outputs":[]}]}